import os
import warnings

import numpy as np

warnings.filterwarnings("ignore")


def get_dataset(name):
    """
    return the dataset corresponding to a given path.
    """
    kwds = [
        "jars",
        "bottles",
        "mugs",
        "airplanes",
        "chairs",
        "cars",
        "tables",
        "sofas",
        "hampson",
        "qp",
    ]
    for k in kwds:
        if k in name:
            return k


def get_generated(data, shape_idx, comp_list, aslist=False):
    acc = []
    for c in data["reconstruct_list"]:
        if comp_list[c]:
            if get_value_from_index(c, shape_idx, data, "generated"):
                acc.append(1)
            else:
                acc.append(0)
    if aslist:
        return acc
    return np.sum(acc)


def load_and_strip(path, metrics_file):
    """
    Loads a metrics file and strips out the first three rows.
    """

    # Should be a list, in order of priority
    assert isinstance(metrics_file, list)

    # Try and find the metrics file
    for m in metrics_file:
        p = os.path.join(path.replace("$DATADIR", os.environ["DATADIR"]), m)
        if os.path.exists(p):
            break
    else:
        raise RuntimeError("couldnt find metrics for {}".format(path))

    # Load the data
    data = np.load(p, allow_pickle=True).item()

    # Build a dictionary from the data
    return {
        k: np.array(i)[3:, :] if k != "reconstruct_list" else i for k, i in data.items()
    }


def get_value_from_index(sample_idx, shape_idx, data, metric, flat=False):
    """
    Return the value corresponding to a specific (sample_idx, shape_idx, metric)
    """
    corrected_index = data["reconstruct_list"].index(sample_idx)
    if not flat:
        return data[metric][corrected_index, shape_idx]
    return data[metric][corrected_index]


def get_single_metric(
    experiment_list,
    reconstruct_list,
    has_one_component_list,
    shape_idx_list,
    metric,
    check_generated,
    check_shape_idx,
):
    """
    Takes a list of experiment data and prunes it to consider only samples that:
        1) have been generated by all experiments
        2) correspond to objects with a single cc
    """

    assert isinstance(experiment_list, list)
    assert isinstance(shape_idx_list, list)
    assert isinstance(reconstruct_list, list)
    assert len(experiment_list) == len(shape_idx_list)

    accumulators = []
    indices = []
    for current_experiment, shape_idx in zip(experiment_list, shape_idx_list):

        # Iterate overall the samples
        accumulator = []
        index = []
        for r in reconstruct_list:

            # Get if our approach generated that sample
            if check_generated is not None:
                sample_generated = np.array(
                    [
                        get_value_from_index(
                            r, check_shape_idx, experiment_list[i], "generated"
                        )
                        for i in check_generated
                    ]
                )
            else:
                sample_generated = np.array([True])

            # If they all generated a sample and there's only one component
            if sample_generated.all() and has_one_component_list[r]:

                # Get the value
                accumulator.append(
                    get_value_from_index(r, shape_idx, current_experiment, metric)
                )
                index.append(r)

        accumulators.append(np.array(accumulator))
        indices.append(np.array(index))

    return list(zip(accumulators, indices))


def get_single_binnable(
    experiment_list,
    reconstruct_list,
    has_one_component_list,
    binnable_metric="nested_binner",
    pad_one_component=True,
):
    """ """

    assert isinstance(experiment_list, list)
    assert isinstance(reconstruct_list, list)
    assert binnable_metric in [
        "nested_binner",
        "truth_tabler",
    ], "Unknown binnable method: {}".format(binnable_metric)

    accumulators = []
    indices = []
    for current_experiment in experiment_list:

        # Iterate overall the samples
        accumulator = []
        index = []
        for r in reconstruct_list:

            # If there's only one component
            if has_one_component_list[r]:

                # Get the value
                if binnable_metric == "nested_binner":
                    accumulator.append(nested_binner(current_experiment, r))

                elif binnable_metric == "truth_tabler":
                    accumulator.append(truth_tabler(current_experiment, r))
                else:
                    raise RuntimeError(
                        "Unknown binnable method: {}".format(binnable_metric)
                    )
                index.append(r)
            else:
                if pad_one_component:
                    accumulator.append(np.nan)
                    index.append(r)

        accumulators.append(np.array(accumulator))
        indices.append(np.array(index))

    return list(zip(accumulators, indices))


def shift_column(experiment, column_from, column_to):
    """
    Shifts a column of a given experiment.
    """
    for metric in experiment:
        if hasattr(experiment[metric], "shape"):
            experiment[metric][:, column_to] = experiment[metric][:, column_from]


def trim_column(experiment, num_columns):
    """
    Removes any columns beyond num_columns
    """
    for metric in experiment:
        if hasattr(experiment[metric], "shape"):
            experiment[metric] = experiment[metric][:, :num_columns]


def overwrite_column(experiment, column_from, column_to):
    """
    Overwrite one column with another column, only if the column_from is not nan
    """
    for metric in experiment:
        if hasattr(experiment[metric], "shape"):
            for r in range(experiment[metric].shape[0]):
                if not np.isnan(experiment[metric][r, column_from]):
                    experiment[metric][r, column_to] = experiment[metric][r, column_from]


def nested_binner(data, sample_idx, r_max_threshold=0.01):
    """
    Takes a data dictionary and the index of a specific object and bins it based on a number of conditions

        Case0: | Cp = Cg | Bp = Bg | Rp=0
        Case1: | Cp = Cg | Bp = Bg | Rp=*
        Case2: | Cp = Cg | Bp = Cg | Rp=0
        Case3: | Cp = Cg | Bp = Cg | Rp=*
        Case4: | Cp = Bg | Bp = Bg | Rp=0
        Case5: | Cp = Bg | Bp = Bg | Rp=*
        Case6: | Cp = Bg | Bp = Cg | Rp=0
        Case7: | Cp = Bg | Bp = Cg | Rp=*
        Case8: | Cp = *  | Bp = *  | Rp=Rg

    """

    # r_max_threshold = 0.01
    # r_max_threshold = np.inf
    # raise RuntimeError("r_max_threshold unset")

    C = 0
    B = 1
    R = 2

    r_chamfer = get_value_from_index(sample_idx, R, data, "chamfer")

    # If R is bad or R is collapsed
    if (r_chamfer > r_max_threshold) or np.isnan(r_chamfer):

        if get_value_from_index(
            sample_idx, C, data, "closer_to_complete"
        ) and not get_value_from_index(
            sample_idx, B, data, "closer_to_complete"
        ):
            if np.isnan(r_chamfer):
                bin = 0
            else:
                bin = 1
        elif get_value_from_index(
            sample_idx, C, data, "closer_to_complete"
        ) and get_value_from_index(
            sample_idx, B, data, "closer_to_complete"
        ):
            if np.isnan(r_chamfer):
                bin = 2
            else:
                bin = 3
        elif not get_value_from_index(
            sample_idx, C, data, "closer_to_complete"
        ) and not get_value_from_index(
            sample_idx, B, data, "closer_to_complete"
        ):
            if np.isnan(r_chamfer):
                bin = 4
            else:
                bin = 5
        elif not get_value_from_index(
            sample_idx, C, data, "closer_to_complete"
        ) and get_value_from_index(
            sample_idx, B, data, "closer_to_complete"
        ):
            if np.isnan(r_chamfer):
                bin = 6
            else:
                bin = 7
        else:
            # This should never happen
            raise RuntimeError
    else:
        bin = 8

    return bin


def truth_tabler(data, sample_idx):
    """
    Takes a data dictionary and the index of a specific object and bins it based on its goodness
    """

    c_max_threshold = 0.005
    b_max_threshold = 0.005
    r_max_threshold = 0.01

    C = 0
    B = 1
    R = 2

    c_chamfer = get_value_from_index(sample_idx, C, data, "chamfer")
    b_chamfer = get_value_from_index(sample_idx, B, data, "chamfer")
    r_chamfer = get_value_from_index(sample_idx, R, data, "chamfer")

    c_good = (c_chamfer <= c_max_threshold) and (not np.isnan(c_chamfer))
    b_good = (b_chamfer <= b_max_threshold) and (not np.isnan(b_chamfer))
    r_good = (r_chamfer <= r_max_threshold) and (not np.isnan(r_chamfer))

    # Truth table
    if c_good and b_good and r_good:
        bin = 0
    elif c_good and b_good and not r_good:
        bin = 1
    elif c_good and not b_good and r_good:
        bin = 2
    elif c_good and not b_good and not r_good:
        bin = 3
    elif not c_good and b_good and r_good:
        bin = 4
    elif not c_good and b_good and not r_good:
        bin = 5
    elif not c_good and not b_good and r_good:
        bin = 6
    elif not c_good and not b_good and not r_good:
        bin = 7
    return bin
